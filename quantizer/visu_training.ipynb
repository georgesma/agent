{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "953874de-6aae-4620-a6f6-6c0f7a21e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as ipw\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "from lib.notebooks import plot_groups_metrics\n",
    "from quantizer import Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7583bdb3-6313-467e-8088-d7b1d4235bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizers_path = glob(\"../out/quantizer/*/\")\n",
    "quantizers_path.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7389042-b54f-476a-b79f-b833d5e4c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_metrics = {}\n",
    "agents_loss = {\n",
    "    \"datasets\": [],\n",
    "    \"inverse_learning_rate\": [],\n",
    "    \"inverse_layers\": [],\n",
    "    \"inverse_dropout_p\": [],\n",
    "    \"direct_learning_rate\": [],\n",
    "    \"direct_layers\": [],\n",
    "    \"direct_dropout_p\": [],\n",
    "    \"direct_estimation_error\": [],\n",
    "    \"inverse_estimation_error\": [],\n",
    "    \"inverse_jerk\": [],\n",
    "    \"inverse_repetition_error\": [],\n",
    "}\n",
    "\n",
    "for agent_path in agents_path:\n",
    "    agent = CommunicativeAgent.reload(agent_path, load_nn=False)\n",
    "    config = agent.config\n",
    "    with open(\"%s/metrics.pickle\" % agent_path, \"rb\") as f:\n",
    "        metrics = pickle.load(f)\n",
    "    \n",
    "    agents_loss[\"datasets\"].append(\",\".join(agent.sound_quantizer.config['dataset']['names']))\n",
    "\n",
    "    agents_loss[\"inverse_learning_rate\"].append(config['training']['inverse_model_learning_rate'])\n",
    "    agents_loss[\"inverse_layers\"].append(f\"{len(config['model']['inverse_model']['hidden_dims'])}x{config['model']['inverse_model']['hidden_dims'][0]}\")\n",
    "    agents_loss[\"inverse_dropout_p\"].append(config['model']['inverse_model']['dropout_p'])\n",
    "\n",
    "    agents_loss[\"direct_learning_rate\"].append(config['training']['direct_model_learning_rate'])\n",
    "    agents_loss[\"direct_layers\"].append(f\"{len(config['model']['direct_model']['hidden_dims'])}x{config['model']['direct_model']['hidden_dims'][0]}\")\n",
    "    agents_loss[\"direct_dropout_p\"].append(config['model']['direct_model']['dropout_p'])\n",
    "\n",
    "    agents_loss[\"datasets\"].append(\",\".join(agent.sound_quantizer.config['dataset']['names']))\n",
    "\n",
    "    final_loss_index = np.argmin(metrics[\"validation\"][\"inverse_model_repetition_error\"])\n",
    "\n",
    "    agents_loss[\"direct_estimation_error\"].append(metrics[\"test\"][\"direct_model_estimation_error\"][final_loss_index])\n",
    "    agents_loss[\"inverse_estimation_error\"].append(metrics[\"test\"][\"inverse_model_estimation_error\"][final_loss_index])\n",
    "    agents_loss[\"inverse_jerk\"].append(metrics[\"test\"][\"inverse_model_jerk\"][final_loss_index])\n",
    "    agents_loss[\"inverse_repetition_error\"].append(metrics[\"test\"][\"inverse_model_repetition_error\"][final_loss_index])\n",
    "    \n",
    "    group_name = \"\\n\".join((\n",
    "        f\"datasets={','.join(agent.sound_quantizer.config['dataset']['names'])}\",\n",
    "        f\"synth_art={agent.synthesizer.config['dataset']['art_type']}\",\n",
    "        f\"jerk_w={config['training']['jerk_loss_weight']}\",\n",
    "        # f\"frame_padding={config['model']['sound_quantizer']['frame_padding']}\",\n",
    "    ))\n",
    "    \n",
    "    if group_name not in groups_metrics:\n",
    "        groups_metrics[group_name] = {}\n",
    "    groups_metrics[group_name][agent_path] = metrics\n",
    "    \n",
    "agents_loss = pd.DataFrame(agents_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0ff75a3-ecaa-4ae1-a517-846c7c5e1374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasets</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>dropout_p</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>commitment_cost</th>\n",
       "      <th>total_loss</th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>vq_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>1x512</td>\n",
       "      <td>0.214496</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>1.482109</td>\n",
       "      <td>0.558082</td>\n",
       "      <td>0.381791</td>\n",
       "      <td>0.176291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>2x256</td>\n",
       "      <td>0.097725</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>1.428386</td>\n",
       "      <td>0.465298</td>\n",
       "      <td>0.382452</td>\n",
       "      <td>0.082846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>1x128</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>1.861183</td>\n",
       "      <td>0.590471</td>\n",
       "      <td>0.385426</td>\n",
       "      <td>0.205045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>1x256</td>\n",
       "      <td>0.269028</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>1.953235</td>\n",
       "      <td>0.531201</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.140338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>1x512</td>\n",
       "      <td>0.485087</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>1.560157</td>\n",
       "      <td>0.567754</td>\n",
       "      <td>0.391204</td>\n",
       "      <td>0.176550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>2x512</td>\n",
       "      <td>0.255175</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.586623</td>\n",
       "      <td>0.510588</td>\n",
       "      <td>0.391880</td>\n",
       "      <td>0.118708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>3x256</td>\n",
       "      <td>0.117205</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.786270</td>\n",
       "      <td>0.466884</td>\n",
       "      <td>0.393574</td>\n",
       "      <td>0.073309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>4x512</td>\n",
       "      <td>0.306015</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>1.938586</td>\n",
       "      <td>0.417760</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.023560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>4x256</td>\n",
       "      <td>0.257288</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1.736629</td>\n",
       "      <td>0.414983</td>\n",
       "      <td>0.394786</td>\n",
       "      <td>0.020196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>pb2007,gb2016,th2016</td>\n",
       "      <td>4x512</td>\n",
       "      <td>0.259563</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>1.380088</td>\n",
       "      <td>0.428938</td>\n",
       "      <td>0.394932</td>\n",
       "      <td>0.034006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datasets hidden_layers  dropout_p  learning_rate  \\\n",
       "45   pb2007,gb2016,th2016         1x512   0.214496       0.001188   \n",
       "33   pb2007,gb2016,th2016         2x256   0.097725       0.000618   \n",
       "38   pb2007,gb2016,th2016         1x128   0.016934       0.001394   \n",
       "96   pb2007,gb2016,th2016         1x256   0.269028       0.001697   \n",
       "82   pb2007,gb2016,th2016         1x512   0.485087       0.000482   \n",
       "9    pb2007,gb2016,th2016         2x512   0.255175       0.000252   \n",
       "36   pb2007,gb2016,th2016         3x256   0.117205       0.000233   \n",
       "47   pb2007,gb2016,th2016         4x512   0.306015       0.000184   \n",
       "97   pb2007,gb2016,th2016         4x256   0.257288       0.000307   \n",
       "100  pb2007,gb2016,th2016         4x512   0.259563       0.000201   \n",
       "\n",
       "     commitment_cost  total_loss  reconstruction_error   vq_loss  \n",
       "45          1.482109    0.558082              0.381791  0.176291  \n",
       "33          1.428386    0.465298              0.382452  0.082846  \n",
       "38          1.861183    0.590471              0.385426  0.205045  \n",
       "96          1.953235    0.531201              0.390863  0.140338  \n",
       "82          1.560157    0.567754              0.391204  0.176550  \n",
       "9           0.586623    0.510588              0.391880  0.118708  \n",
       "36          0.786270    0.466884              0.393574  0.073309  \n",
       "47          1.938586    0.417760              0.394200  0.023560  \n",
       "97          1.736629    0.414983              0.394786  0.020196  \n",
       "100         1.380088    0.428938              0.394932  0.034006  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizers_loss.sort_values(\"reconstruction_error\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af89a93-0241-4b9d-847c-48a90a803c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3ff47880324adfb29d926c30fa7b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='split_name', index=1, options=('train', 'validation'), value='valiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_name = [\n",
    "    \"total_loss\",\n",
    "    \"reconstruction_error\",\n",
    "    \"vq_loss\",\n",
    "]\n",
    "\n",
    "def show_metrics(split_name=\"validation\"):\n",
    "    plot_groups_metrics(groups_metrics, metrics_name, split_name)\n",
    "display(ipw.interactive(show_metrics, split_name=[\"train\", \"validation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338a024-b197-4365-9257-4843a231315c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

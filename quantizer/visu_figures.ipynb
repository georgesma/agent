{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e543cd-22c9-4000-a9e8-c71e0e8a0d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "import ipywidgets as ipw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from quantizer import Quantizer\n",
    "from lib.dataset_wrapper import Dataset\n",
    "from lib import utils\n",
    "from lib import abx_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b49ea09-c807-4eff-a73a-99e1516ef3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABX_NB_SAMPLES = 50\n",
    "QUANTIZER_ABX_DISTANCE = {\n",
    "    \"quantized_latent\": {\n",
    "        \"metric\": \"cosine\",\n",
    "        \"weight\": 1,\n",
    "    }\n",
    "}\n",
    "NB_TRAINING = 5\n",
    "REGULAR_MODALITIES = [[\"cepstrum\"], [\"art_params\"], [\"cepstrum\", \"art_params\"]]\n",
    "LATE_FUSION_DATASETS = [\"pb2007\"]\n",
    "LATE_FUSION_MODALITIES = [\"cepstrum\", \"art_params\"]\n",
    "LATE_FUSION_RANGE = [-1, 1]\n",
    "LATE_FUSION_NB_STEPS = 10\n",
    "LATE_FUSION_WEIGHTS = 10 ** np.linspace(*LATE_FUSION_RANGE, LATE_FUSION_NB_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f86840-98e0-4c3e-bec8-65433ba88418",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizers_path = glob(\"../out/quantizer/*/\")\n",
    "quantizers_path.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb30d549-f6d0-4824-ba44-f423d0c92da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizers_abx_matrices = utils.pickle_load(\"../out/quantizer/abx_cache.pickle\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ba90d1-e216-404e-a4e0-52d54ef2129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190b48d4b4c442a6baeb2490249e3bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for quantizer_path in tqdm(quantizers_path):    \n",
    "    if quantizer_path not in quantizers_abx_matrices:\n",
    "        quantizers_abx_matrices[quantizer_path] = {}\n",
    "    quantizer_abx_matrices = quantizers_abx_matrices[quantizer_path]\n",
    "    \n",
    "    distance = QUANTIZER_ABX_DISTANCE\n",
    "    distance_signature = abx_utils.get_distance_signature(distance)\n",
    "    if distance_signature in quantizer_abx_matrices: continue\n",
    "    \n",
    "    quantizer = Quantizer.reload(quantizer_path)\n",
    "    \n",
    "    main_dataset = quantizer.main_dataset\n",
    "    quantizer_lab = quantizer.get_datasplit_lab(2)\n",
    "    quantizer_features = quantizer.autoencode_datasplit(2)\n",
    "\n",
    "    consonants = main_dataset.phones_infos[\"consonants\"]\n",
    "    vowels = main_dataset.phones_infos[\"vowels\"]\n",
    "    consonants_indexes = abx_utils.get_datasets_phones_indexes(quantizer_lab, consonants, vowels)\n",
    "\n",
    "    abx_matrix = abx_utils.get_abx_matrix(consonants, consonants_indexes, quantizer_features, distance, ABX_NB_SAMPLES)\n",
    "    quantizer_abx_matrices[distance_signature] = abx_matrix\n",
    "    utils.pickle_dump(\"../out/quantizer/abx_cache.pickle\", quantizers_abx_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16b8114-bbe5-4995-ab44-e4d299b1a453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40afa7ea73043db902cd748933cc43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_quantizers_config = utils.read_yaml_file(\"quantizer_final_configs.yaml\")\n",
    "late_fusion_abx_matrices = utils.pickle_load(\"../out/quantizer/late_fusion_cache.pickle\", {})\n",
    "\n",
    "for late_fusion_dataset in LATE_FUSION_DATASETS:\n",
    "    for i_training in tqdm(range(NB_TRAINING)):\n",
    "        quantizers_features = {}\n",
    "        quantizers_signature = []\n",
    "        abx_distance = {}\n",
    "        \n",
    "        for late_fusion_modality in LATE_FUSION_MODALITIES:\n",
    "            quantizer_config = final_quantizers_config[\"%s-%s\" % (late_fusion_dataset, late_fusion_modality)]\n",
    "            quantizer_config[\"dataset\"][\"datasplit_seed\"] = i_training\n",
    "            quantizer_signature = utils.get_variable_signature(quantizer_config)\n",
    "            quantizer_path = \"../out/quantizer/%s-%s/\" % (quantizer_signature, i_training)\n",
    "            quantizer = Quantizer.reload(quantizer_path)\n",
    "            quantizer_features = quantizer.autoencode_datasplit(2)\n",
    "            \n",
    "            quantizers_signature.append(quantizer_signature)\n",
    "            abx_distance[late_fusion_modality] = {\n",
    "                \"metric\": \"cosine\",\n",
    "                \"weight\": 1,\n",
    "            }\n",
    "            \n",
    "            for dataset_name, dataset_features in quantizer_features.items():\n",
    "                if dataset_name not in quantizers_features:\n",
    "                    quantizers_features[dataset_name] = {}\n",
    "                quantizers_features[dataset_name][late_fusion_modality] = {}\n",
    "                \n",
    "                for item_name, item_quantized_latent in dataset_features[\"quantized_latent\"].items():\n",
    "                    quantizers_features[dataset_name][late_fusion_modality][item_name] = item_quantized_latent\n",
    "        \n",
    "        main_dataset = quantizer.main_dataset\n",
    "        quantizer_lab = quantizer.get_datasplit_lab(2)\n",
    "        \n",
    "        consonants = main_dataset.phones_infos[\"consonants\"]\n",
    "        vowels = main_dataset.phones_infos[\"vowels\"]\n",
    "        consonants_indexes = abx_utils.get_datasets_phones_indexes(quantizer_lab, consonants, vowels)\n",
    "\n",
    "        for late_fusion_weight in tqdm(LATE_FUSION_WEIGHTS, leave=False):\n",
    "            abx_distance[late_fusion_modality][\"weight\"] = late_fusion_weight\n",
    "            distance_signature = abx_utils.get_distance_signature(abx_distance)\n",
    "            cache_key = \"%s-%s\" % (abx_distance, i_training)\n",
    "            if cache_key in late_fusion_abx_matrices: continue\n",
    "            abx_matrix = abx_utils.get_abx_matrix(consonants, consonants_indexes, quantizers_features, abx_distance, ABX_NB_SAMPLES)\n",
    "            late_fusion_abx_matrices[cache_key] = abx_matrix\n",
    "            utils.pickle_dump(\"../out/quantizer/late_fusion_cache.pickle\", late_fusion_abx_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1192e773-a919-4d3d-a01d-d1b57b789ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../out/quantizer/3bd561b0142a6903d81252a250939cf6-0//config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8a3d7cdf2c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mquantizer_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../out/quantizer/%s-%s/\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfig_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mquantizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_nn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mconsonants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphones_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"consonants\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mvowels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphones_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vowels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/these/code/code-papier/lpcnet_agents/quantizer/quantizer.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(save_path, load_nn)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_nn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/config.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mquantizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_nn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_nn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../out/quantizer/3bd561b0142a6903d81252a250939cf6-0//config.yaml'"
     ]
    }
   ],
   "source": [
    "distance_signature = abx_utils.get_distance_signature(QUANTIZER_ABX_DISTANCE)\n",
    "final_quantizers_scores = {}\n",
    "\n",
    "for config_name, config in final_quantizers_config.items():\n",
    "    config_scores = {\n",
    "        \"global\": [],\n",
    "        \"manner\": [],\n",
    "        \"place\": [],\n",
    "    }\n",
    "    \n",
    "    for i_training in range(NB_TRAINING):\n",
    "        config[\"dataset\"][\"datasplit_seed\"] = i_training\n",
    "        config_signature = utils.get_variable_signature(config)\n",
    "        quantizer_path = \"../out/quantizer/%s-%s/\" % (config_signature, i_training)\n",
    "        \n",
    "        quantizer = Quantizer.reload(quantizer_path, load_nn=False)\n",
    "        consonants = quantizer.main_dataset.phones_infos[\"consonants\"]\n",
    "        vowels = quantizer.main_dataset.phones_infos[\"vowels\"]\n",
    "        quantizer_abx_matrix = quantizers_abx_matrices[quantizer_path][distance_signature]\n",
    "        quantizer_groups_score = abx_utils.get_groups_score(consonants, quantizer_abx_matrix, quantizer.main_dataset.phones_infos[\"consonant_groups\"])\n",
    "        quantizer_global_score = abx_utils.get_global_score(quantizer_abx_matrix)\n",
    "\n",
    "        config_scores[\"global\"].append(quantizer_global_score)\n",
    "        config_scores[\"manner\"].append(quantizer_groups_score[\"manner\"])\n",
    "        config_scores[\"place\"].append(quantizer_groups_score[\"place\"])\n",
    "\n",
    "    config_datasets = \",\".join(config[\"dataset\"][\"names\"])\n",
    "    config_modalities = \",\".join(config[\"dataset\"][\"data_types\"])\n",
    "    if config_datasets not in final_quantizers_scores:\n",
    "        final_quantizers_scores[config_datasets] = {}\n",
    "    final_quantizers_scores[config_datasets][config_modalities] = config_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4532bdd-7d6b-4df1-ae55-8cc0ac0bd9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUSION_COLORMAP = colormaps[\"cool\"]\n",
    "colors = {\n",
    "    \"cepstrum\": \"tab:orange\",\n",
    "    \"art_params\": \"tab:blue\",\n",
    "    \"cepstrum,art_params\": \"tab:green\",\n",
    "}\n",
    "\n",
    "for late_fusion_dataset in LATE_FUSION_DATASETS:\n",
    "    dataset = Dataset(late_fusion_dataset)\n",
    "    consonants = dataset.phones_infos[\"consonants\"]\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot(aspect=\"equal\")\n",
    "    ax.set_xlim(50, 100)\n",
    "    ax.set_ylim(50, 100)\n",
    "    ax.set_xlabel(\"Manner\")\n",
    "    ax.set_ylabel(\"Place\")\n",
    "    ax.set_title(late_fusion_dataset)\n",
    "    \n",
    "    \n",
    "    for modalities in REGULAR_MODALITIES:\n",
    "        modality = \",\".join(modalities)\n",
    "        modality_score = final_quantizers_scores[late_fusion_dataset][modality]\n",
    "        color = colors[modality]\n",
    "        \n",
    "        # for i_training in range(NB_TRAINING):\n",
    "        #     ax.scatter(modality_score[\"manner\"][i_training], modality_score[\"place\"][i_training], color=color, s=6)\n",
    "            \n",
    "        manner_mean = np.mean(modality_score[\"manner\"])\n",
    "        place_mean = np.mean(modality_score[\"place\"])\n",
    "        ax.scatter(manner_mean, place_mean, color=color)\n",
    "    \n",
    "    abx_distance = {}\n",
    "    for late_fusion_modality in LATE_FUSION_MODALITIES:\n",
    "        abx_distance[late_fusion_modality] = {\n",
    "            \"metric\": \"cosine\",\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "    \n",
    "    weights_score = []\n",
    "    for i_weight, late_fusion_weight in enumerate(LATE_FUSION_WEIGHTS):\n",
    "        weight_scores = {\n",
    "            \"manner\": [],\n",
    "            \"place\": [],\n",
    "        }\n",
    "        cmap_index = 1 - i_weight / (LATE_FUSION_NB_STEPS-1)\n",
    "        weight_color = FUSION_COLORMAP(cmap_index)\n",
    "        \n",
    "        for i_training in range(NB_TRAINING):\n",
    "            abx_distance[late_fusion_modality][\"weight\"] = late_fusion_weight\n",
    "            \n",
    "            distance_signature = abx_utils.get_distance_signature(abx_distance)\n",
    "            cache_key = \"%s-%s\" % (abx_distance, i_training)\n",
    "            abx_matrix = late_fusion_abx_matrices[cache_key]\n",
    "            quantizer_groups_score = abx_utils.get_groups_score(consonants, abx_matrix, dataset.phones_infos[\"consonant_groups\"])\n",
    "            weight_scores[\"manner\"].append(quantizer_groups_score[\"manner\"])\n",
    "            weight_scores[\"place\"].append(quantizer_groups_score[\"place\"])\n",
    "            # ax.scatter(quantizer_groups_score[\"manner\"], quantizer_groups_score[\"place\"], color=weight_color, s=4)\n",
    "        \n",
    "        weight_score = {\n",
    "            \"manner\": np.mean(weight_scores[\"manner\"]),\n",
    "            \"place\": np.mean(weight_scores[\"place\"]),\n",
    "        }\n",
    "        weights_score.append(weight_score)\n",
    "    \n",
    "    for i_segment in range(LATE_FUSION_NB_STEPS-1):\n",
    "        cmap_index = 1 - i_segment / (LATE_FUSION_NB_STEPS-2)\n",
    "        segment_color = FUSION_COLORMAP(cmap_index)\n",
    "        \n",
    "        segment_start = weights_score[i_segment]\n",
    "        segment_end = weights_score[i_segment+1]\n",
    "        ax.plot((segment_start[\"manner\"], segment_end[\"manner\"]), (segment_start[\"place\"], segment_end[\"place\"]), color=segment_color, linewidth=3)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec44f74-574b-4f5a-be76-34b20735f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUSION_COLORMAP = colormaps[\"cool\"]\n",
    "colors = {\n",
    "    \"cepstrum\": \"tab:orange\",\n",
    "    \"art_params\": \"tab:blue\",\n",
    "    \"cepstrum,art_params\": \"tab:green\",\n",
    "}\n",
    "\n",
    "for late_fusion_dataset in LATE_FUSION_DATASETS:\n",
    "    dataset = Dataset(late_fusion_dataset)\n",
    "    consonants = dataset.phones_infos[\"consonants\"]\n",
    "    nb_modalities = len(REGULAR_MODALITIES)\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    # ax.set_xlim(50, 100)\n",
    "    ax.set_ylim(50, 100)\n",
    "    ax.set_title(\"Global ABX score (%s)\" % late_fusion_dataset)\n",
    "    \n",
    "    for i_modality, modalities in enumerate(REGULAR_MODALITIES):\n",
    "        modality = \",\".join(modalities)\n",
    "        modality_score = final_quantizers_scores[late_fusion_dataset][modality]\n",
    "        color = colors[modality]\n",
    "        \n",
    "        # for i_training in range(NB_TRAINING):\n",
    "        #     ax.scatter(modality_score[\"manner\"][i_training], modality_score[\"place\"][i_training], color=color, s=6)\n",
    "        \n",
    "        global_mean = np.mean(modality_score[\"global\"])\n",
    "        ax.bar(i_modality, global_mean, color=color)\n",
    "    \n",
    "    abx_distance = {}\n",
    "    for late_fusion_modality in LATE_FUSION_MODALITIES:\n",
    "        abx_distance[late_fusion_modality] = {\n",
    "            \"metric\": \"cosine\",\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "    \n",
    "    weights_score = []\n",
    "    for i_weight, late_fusion_weight in enumerate(LATE_FUSION_WEIGHTS):\n",
    "        weight_scores = []\n",
    "        cmap_index = 1 - i_weight / (LATE_FUSION_NB_STEPS-1)\n",
    "        weight_color = FUSION_COLORMAP(cmap_index)\n",
    "        \n",
    "        for i_training in range(NB_TRAINING):\n",
    "            abx_distance[late_fusion_modality][\"weight\"] = late_fusion_weight\n",
    "            \n",
    "            distance_signature = abx_utils.get_distance_signature(abx_distance)\n",
    "            cache_key = \"%s-%s\" % (abx_distance, i_training)\n",
    "            abx_matrix = late_fusion_abx_matrices[cache_key]\n",
    "            quantizer_global_score = abx_utils.get_global_score(abx_matrix)\n",
    "            weight_scores.append(quantizer_global_score)\n",
    "        \n",
    "        weight_score = np.mean(weight_scores)\n",
    "        ax.bar(nb_modalities + i_weight, weight_score, color=weight_color)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa0686-6723-46b7-8db8-1a936bcfd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_quantizers_variations = {}\n",
    "\n",
    "for config_name, config in final_quantizers_config.items():\n",
    "    consonants_units_change = 0\n",
    "    consonants_len = 0\n",
    "    \n",
    "    for i_training in range(NB_TRAINING):\n",
    "        config[\"dataset\"][\"datasplit_seed\"] = i_training\n",
    "        config_signature = utils.get_variable_signature(config)\n",
    "        quantizer_path = \"../out/quantizer/%s-%s/\" % (config_signature, i_training)\n",
    "        \n",
    "        quantizer = Quantizer.reload(quantizer_path)\n",
    "        main_dataset = quantizer.main_dataset\n",
    "        consonants = main_dataset.phones_infos[\"consonants\"]\n",
    "        quantizer_lab = quantizer.get_datasplit_lab(2)\n",
    "        quantizer_features = quantizer.autoencode_datasplit(2)\n",
    "        consonants_indexes = abx_utils.get_datasets_phones_indexes(quantizer_lab, consonants, vowels)\n",
    "        \n",
    "        for consonant_name, consonant_indexes in consonants_indexes.items():\n",
    "            for consonant_index in consonant_indexes:\n",
    "                consonant_units = np.argmax(abx_utils.get_phone_features(quantizer_features, \"quantized_index\", consonant_index), axis=1)\n",
    "                nb_change = np.abs(np.diff(consonant_units)).clip(0, 1).sum()\n",
    "                nb_frames = len(consonant_units)\n",
    "                consonants_units_change += nb_change\n",
    "                consonants_len += nb_frames\n",
    "\n",
    "    config_datasets = \",\".join(config[\"dataset\"][\"names\"])\n",
    "    config_modalities = \",\".join(config[\"dataset\"][\"data_types\"])\n",
    "    if config_datasets not in final_quantizers_variations:\n",
    "        final_quantizers_variations[config_datasets] = {}\n",
    "    final_quantizers_variations[config_datasets][config_modalities] = consonants_units_change / consonants_len * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da03c7d-751f-4d24-8bd8-3b69a6b54c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUSION_COLORMAP = colormaps[\"cool\"]\n",
    "colors = {\n",
    "    \"cepstrum\": \"tab:orange\",\n",
    "    \"art_params\": \"tab:blue\",\n",
    "    \"cepstrum,art_params\": \"tab:green\",\n",
    "}\n",
    "\n",
    "for late_fusion_dataset in LATE_FUSION_DATASETS:\n",
    "    dataset = Dataset(late_fusion_dataset)\n",
    "    consonants = dataset.phones_infos[\"consonants\"]\n",
    "    nb_modalities = len(REGULAR_MODALITIES)\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    ax.set_title(\"Units variation %% during consonants (%s)\" % late_fusion_dataset)\n",
    "    xticks = []\n",
    "    \n",
    "    for i_modality, modalities in enumerate(REGULAR_MODALITIES):\n",
    "        modality = \",\".join(modalities)\n",
    "        xticks.append(modality)\n",
    "        \n",
    "        modality_score = final_quantizers_variations[late_fusion_dataset][modality]\n",
    "        color = colors[modality]\n",
    "        \n",
    "        # for i_training in range(NB_TRAINING):\n",
    "        #     ax.scatter(modality_score[\"manner\"][i_training], modality_score[\"place\"][i_training], color=color, s=6)\n",
    "        \n",
    "        ax.bar(i_modality, modality_score, color=color)\n",
    "    ax.set_xticks(range(len(xticks)), xticks)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693c3f4-e6dd-4e08-935a-6e2c1a46c2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
